{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOOIQkqOJzzhH7VUgnHnEBq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Esha-tur-Razia/CS261F21PID41/blob/main/Implement%20to%20retrieve%20%20documents%20by%20Probabilistic%2C%20Non-Overlapped%20List%20and%20Proximal%20Nodes%20Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample document database with associated terms\n",
        "document_database = {\n",
        "    \"document1\": [\"machine learning\", \"data science\"],\n",
        "    \"document2\": [\"data visualization\", \"analytics\"],\n",
        "    \"document3\": [\"machine learning\", \"deep learning\"],\n",
        "    \"document4\": [\"data visualization\", \"charts\"],\n",
        "}\n",
        "\n",
        "# Terms of interest\n",
        "terms_of_interest = [\"machine learning\", \"data visualization\"]\n",
        "\n",
        "# Step 2: Retrieve Documents per Term\n",
        "document_lists_per_term = {}\n",
        "\n",
        "for term in terms_of_interest:\n",
        "    document_lists_per_term[term] = [doc for doc, terms in document_database.items() if term in terms]\n",
        "\n",
        "# Step 3: Combine Lists for Non-Overlapping Results\n",
        "combined_documents = set()\n",
        "for term, document_list in document_lists_per_term.items():\n",
        "    combined_documents.update(document_list)\n",
        "\n",
        "# Step 4: Present Results\n",
        "print(f\"Documents related to terms of interest ({', '.join(terms_of_interest)}):\")\n",
        "for doc in combined_documents:\n",
        "    print(doc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xaUw3KY1-J1p",
        "outputId": "c1052ad1-19ac-4df2-e5a2-6bb003ce26e8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Documents related to terms of interest (machine learning, data visualization):\n",
            "document2\n",
            "document1\n",
            "document3\n",
            "document4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from collections import defaultdict\n",
        "\n",
        "# Sample document collection\n",
        "documents = [\n",
        "    \"document 1 is a collection of words\",\n",
        "    \"document 2 contains some words\",\n",
        "    \"document 3 is also made up of words\"\n",
        "]\n",
        "\n",
        "# Sample user query\n",
        "query = \"query words collection\"\n",
        "\n",
        "# Preprocessing: Tokenization and lowercasing\n",
        "def preprocess(text):\n",
        "    text = text.lower()\n",
        "    return re.findall(r'\\w+', text)\n",
        "\n",
        "# Create a vocabulary from the document collection\n",
        "vocab = set()\n",
        "for doc in documents:\n",
        "    terms = preprocess(doc)\n",
        "    vocab.update(terms)\n",
        "\n",
        "# Term Weighting: Binary weights\n",
        "def binary_weights(doc):\n",
        "    terms = preprocess(doc)\n",
        "    doc_vector = {term: 1 if term in terms else 0 for term in vocab}\n",
        "    return doc_vector\n",
        "\n",
        "# Query Representation: Binary vector\n",
        "query_vector = binary_weights(query)\n",
        "\n",
        "# Document Scoring: Jaccard coefficient\n",
        "def jaccard_similarity(doc_vector, query_vector):\n",
        "    intersection = sum(doc_vector[term] * query_vector[term] for term in vocab)\n",
        "    union = sum(doc_vector[term] + query_vector[term] for term in vocab)\n",
        "    return intersection / union\n",
        "\n",
        "# Rank documents based on Jaccard similarity\n",
        "document_scores = defaultdict(float)\n",
        "for i, doc in enumerate(documents):\n",
        "    doc_vector = binary_weights(doc)\n",
        "    similarity = jaccard_similarity(doc_vector, query_vector)\n",
        "    document_scores[i] = similarity\n",
        "\n",
        "# Sort documents by score in descending order\n",
        "sorted_documents = sorted(document_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# Retrieve Top-K Documents\n",
        "K = 2  # You can adjust K based on your preferences\n",
        "top_documents = [documents[i] for i, _ in sorted_documents[:K]]\n",
        "\n",
        "# Presentation of Results\n",
        "for i, doc in enumerate(top_documents, 1):\n",
        "    print(f\"Result {i}: {doc}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Io4nCQr8-aKJ",
        "outputId": "da6c69da-2b65-4be4-f867-20e937785260"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result 1: document 1 is a collection of words\n",
            "Result 2: document 2 contains some words\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample network representation (adjacency list)\n",
        "network = {\n",
        "    \"NASA\": [\"document1\", \"document2\"],\n",
        "    \"astronauts\": [\"document1\", \"document3\"],\n",
        "    \"space missions\": [\"document2\", \"document4\"],\n",
        "    \"machine learning\": [\"document3\", \"document5\"],\n",
        "}\n",
        "\n",
        "# User's query and proximal nodes\n",
        "user_query = \"space exploration\"\n",
        "proximal_nodes = [\"NASA\", \"astronauts\", \"space missions\"]\n",
        "\n",
        "# Step 3: Retrieve Connected Documents\n",
        "connected_documents = set()\n",
        "for node in proximal_nodes:\n",
        "    if node in network:\n",
        "        connected_documents.update(network[node])\n",
        "\n",
        "# Step 4: Present Results\n",
        "print(f\"Documents related to the proximal nodes ({', '.join(proximal_nodes)}):\")\n",
        "for doc in connected_documents:\n",
        "    print(doc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5stWjxk9-n6p",
        "outputId": "3f59c710-7342-4c8b-f3b8-c8b00ef442a6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Documents related to the proximal nodes (NASA, astronauts, space missions):\n",
            "document2\n",
            "document1\n",
            "document3\n",
            "document4\n"
          ]
        }
      ]
    }
  ]
}